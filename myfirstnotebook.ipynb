{"cells":[{"cell_type":"markdown","source":["# First notebook for Spark using python\nIn this notebook we define how to use spark creating a session and changing the schema"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"36614b72-5ab0-421a-806b-df5b0bd05ae6","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Do the imports\nfrom pyspark.sql import SparkSession"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"457c0afb-ed09-4b74-be15-2d70a938e951","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Create a session\nspark =SparkSession.builder.appName('Basics').getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b42e4bf7-fa34-46d4-b700-8dc12082a87f","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# upload the json file to DBFS\ndf = spark.read.json(\"/FileStore/tables/people.json\")\ndf.show()\ndf.printSchema()\nprint(df.columns)\ndf.describe().show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"dbfc5ea1-52a6-4559-b310-0660773c90e1","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["+----+-------+\n| age|   name|\n+----+-------+\n|null|Michael|\n|  30|   Andy|\n|  19| Justin|\n+----+-------+\n\nroot\n |-- age: long (nullable = true)\n |-- name: string (nullable = true)\n\n['age', 'name']\n+-------+------------------+-------+\n|summary|               age|   name|\n+-------+------------------+-------+\n|  count|                 2|      3|\n|   mean|              24.5|   null|\n| stddev|7.7781745930520225|   null|\n|    min|                19|   Andy|\n|    max|                30|Michael|\n+-------+------------------+-------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":["# import structs so we can change schema\nfrom pyspark.sql.types import StructField, StringType, IntegerType, StructType"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1582671d-76fe-44f6-820c-aeb2ddf74dad","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# define schema\ndata_schema = [StructField('age', IntegerType(), True),\n              StructField('name', StringType(), True)]\nfinal_struct = StructType(fields= data_schema)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"cbf2d494-8e37-4ddd-92b2-6530fe48a3af","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# read json with new schema\ndf = spark.read.json(\"/FileStore/tables/people.json\", final_struct)\ndf.printSchema()\ndf.describe().show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"175688a4-a941-4e98-b126-c2bada3074e4","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["root\n |-- age: integer (nullable = true)\n |-- name: string (nullable = true)\n\n+-------+------------------+-------+\n|summary|               age|   name|\n+-------+------------------+-------+\n|  count|                 2|      3|\n|   mean|              24.5|   null|\n| stddev|7.7781745930520225|   null|\n|    min|                19|   Andy|\n|    max|                30|Michael|\n+-------+------------------+-------+\n\n"]}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c2f90c35-6664-4057-a9e9-7353a16fe534","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"myfirstnotebook","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3951189803901544}},"nbformat":4,"nbformat_minor":0}
